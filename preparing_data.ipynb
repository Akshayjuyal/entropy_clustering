{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.10 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_info_df = pd.DataFrame.from_records([pd.read_pickle(\"../data/closest_haplotypes_all_trimmed_2_fixed_3444_tn93\")])\n",
    "# records = SeqIO.parse(\"../data/sequences_2021-03-04_08-34_trimmed_50_l_r_no_amb_aligned_before_march_5_3757_total_sorted.fasta\", 'fasta')\n",
    "# records = tuple(SeqIO.parse(\"../data/cog_all_trimmed_no_amb_aligned.sorted.fasta\", 'fasta'))\n",
    "records = tuple(SeqIO.parse(\"../data/sequences_2021-03-04_08-34_trimmed_50_l_r_no_amb_aligned_before_march_5_3757_total_sorted.fasta\", 'fasta'))\n",
    "\n",
    "# with open(\"../data/closest_haplotypes_all_trimmed_2_fixed_3444_tn93\",\"rb\") as pkl:\n",
    "#     data=pickle.load(pkl)\n",
    "# cluster_info_dict = dict(pd.read_pickle(\"../data/closest_haplotypes_all_trimmed_2_fixed_3444_tn93\"))\n",
    "cluster_info_dict = dict(pd.read_pickle(\"../data/closest_haplotypes_500k_trimmed_tn93_before_march_5_0_005\"))\n",
    "# print(len(tuple(records)))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_name=[]\n",
    "sequences=[]\n",
    "for seq_record in records:  # (generator)\n",
    "        sequence_name.append(seq_record.id)\n",
    "        sequences.append(seq_record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=[]\n",
    "for val in sequence_name:\n",
    "    cluster.append(cluster_info_dict[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dict = {'sequence_name':sequence_name , 'cluster_name':cluster,'sequence': sequences}\n",
    "fasta_df = pd.DataFrame(data=fasta_dict).drop_duplicates(subset='sequence_name', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malaysia/IMR_WC1170/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>(A, A, G, A, A, A, G, G, T, T, T, A, T, A, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hangzhou/ZJU-06/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>(-, T, T, C, A, A, C, G, T, T, T, A, T, A, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hangzhou/ZJU-08/2020</td>\n",
       "      <td>3</td>\n",
       "      <td>(-, -, -, -, G, A, G, A, T, T, T, A, T, A, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denmark/SSI-102/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>(-, -, -, -, A, A, G, C, T, T, T, A, T, A, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hangzhou/ZJU-03/2020</td>\n",
       "      <td>4</td>\n",
       "      <td>(-, -, -, -, -, A, G, A, T, T, T, A, T, A, C, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>England/20099071904/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>(-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>USA/UT-01320/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>(-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>USA/CA-SCCPHD-UC123/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>(-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>USA/CO-CDPHE-2003040178/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>(-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>Australia/WA27/2020</td>\n",
       "      <td>13</td>\n",
       "      <td>(-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3688 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sequence_name cluster_name  \\\n",
       "0         Malaysia/IMR_WC1170/2020            4   \n",
       "1             Hangzhou/ZJU-06/2020            0   \n",
       "2             Hangzhou/ZJU-08/2020            3   \n",
       "3             Denmark/SSI-102/2020            2   \n",
       "4             Hangzhou/ZJU-03/2020            4   \n",
       "...                            ...          ...   \n",
       "3683      England/20099071904/2020           13   \n",
       "3684             USA/UT-01320/2020           13   \n",
       "3685      USA/CA-SCCPHD-UC123/2020           13   \n",
       "3686  USA/CO-CDPHE-2003040178/2020           13   \n",
       "3687           Australia/WA27/2020           13   \n",
       "\n",
       "                                               sequence  \n",
       "0     (A, A, G, A, A, A, G, G, T, T, T, A, T, A, C, ...  \n",
       "1     (-, T, T, C, A, A, C, G, T, T, T, A, T, A, C, ...  \n",
       "2     (-, -, -, -, G, A, G, A, T, T, T, A, T, A, C, ...  \n",
       "3     (-, -, -, -, A, A, G, C, T, T, T, A, T, A, C, ...  \n",
       "4     (-, -, -, -, -, A, G, A, T, T, T, A, T, A, C, ...  \n",
       "...                                                 ...  \n",
       "3683  (-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...  \n",
       "3684  (-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...  \n",
       "3685  (-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...  \n",
       "3686  (-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...  \n",
       "3687  (-, -, -, -, -, -, -, -, -, -, -, -, -, -, -, ...  \n",
       "\n",
       "[3688 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data=[]\n",
    "for val in fasta_df.values:\n",
    "    seq=list(val[2])\n",
    "    seq.insert(0,val[0])\n",
    "    seq_data.append(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = np.array(seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Malaysia/IMR_WC1170/2020', 'A', 'A', ..., '-', '-', '-'],\n",
       "       ['Hangzhou/ZJU-06/2020', '-', 'T', ..., '-', '-', '-'],\n",
       "       ['Hangzhou/ZJU-08/2020', '-', '-', ..., '-', '-', '-'],\n",
       "       ...,\n",
       "       ['USA/CA-SCCPHD-UC123/2020', '-', '-', ..., '-', '-', '-'],\n",
       "       ['USA/CO-CDPHE-2003040178/2020', '-', '-', ..., '-', '-', '-'],\n",
       "       ['Australia/WA27/2020', '-', '-', ..., '-', '-', '-']],\n",
       "      dtype='<U47')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29891"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_data.T[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29891/29891 [02:20<00:00, 213.09it/s]\n"
     ]
    }
   ],
   "source": [
    "entropys_list=[]\n",
    "for val in tqdm(seq_data.T[1:]):\n",
    "    dash,A,C,T,G,entropy=0,0,0,0,0,0\n",
    "    for neu in val:\n",
    "        if neu == \"-\":\n",
    "            dash+=1\n",
    "        elif neu == \"A\":\n",
    "            A+=1\n",
    "        elif neu == \"C\":\n",
    "            C+=1\n",
    "        elif neu == \"T\":\n",
    "            T+=1\n",
    "        elif neu == \"G\":\n",
    "            G+=1\n",
    "    total = A+C+T+G\n",
    "    if (total > 0):\n",
    "        n_a_freq = A/ total\n",
    "        n_c_freq = C/ total\n",
    "        n_t_freq = T/ total\n",
    "        n_g_freq = G/ total\n",
    "        entropy_a = n_a_freq * math.log2(n_a_freq) if n_a_freq > 0 else 0\n",
    "        entropy_c = n_c_freq * math.log2(n_c_freq) if n_c_freq > 0 else 0\n",
    "        entropy_g = n_t_freq * math.log2(n_t_freq) if n_t_freq > 0 else 0\n",
    "        entropy_t = n_g_freq * math.log2(n_g_freq) if n_g_freq > 0 else 0\n",
    "        entropy = entropy + entropy_a + entropy_c + entropy_g + entropy_t\n",
    "    entropys_list.append(abs(entropy))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropys_list\n",
    "sorted_tags_wrt_entropy = np.argsort(entropys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29890,     6,     7, 29888, 29887,     1,     2,     3,   240,\n",
       "        3036, 23402, 14407, 29889,     4, 28143,  8781, 11082, 29867,\n",
       "          30, 29866,    18, 28882, 28881, 28880,    20,    10, 26143,\n",
       "       29869, 14804, 29863, 29861, 29860, 29858, 29857, 29855,    12,\n",
       "          15,    16,    19, 29880,    25, 18059, 29872,    24, 29741,\n",
       "       29871,    27,    26,    22, 17857,    56, 17746,    54, 27045,\n",
       "       29868,    36,    34, 25562, 29856,    38,  1396, 29854, 29853,\n",
       "       28687,   152,  9476,  1058, 28862, 28656,   154, 25978, 15323,\n",
       "       25349,  5571,  2557,  2479, 26529,   513, 17246, 29094,  1439,\n",
       "       29846,  2890, 17372, 29634, 20267, 29302, 28076, 11751, 28877,\n",
       "       29708,  9961, 24033, 13928, 29710, 21706, 26728,  4401, 18876,\n",
       "         265])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_tags_wrt_entropy[::-1][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find N Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = tuple(SeqIO.parse(\"../data/sequences_2021-03-04_08-34_trimmed_50_l_r_no_amb_aligned_before_march_5_3757_total_sorted.fasta\", 'fasta'))\n",
    "cluster_info_dict = dict(pd.read_pickle(\"../data/closest_haplotypes_500k_trimmed_tn93_before_march_5_0_005\"))\n",
    "sequence_name,sequences,cluster=[],[],[]\n",
    "\n",
    "for seq_record in records:  # (generator)\n",
    "        sequence_name.append(seq_record.id)\n",
    "        sequences.append(seq_record.seq)\n",
    "for val in sequence_name:\n",
    "    cluster.append(cluster_info_dict[val])\n",
    "fasta_dict = {'sequence_name':sequence_name , 'cluster_name':cluster,'sequence': sequences}\n",
    "fasta_df = pd.DataFrame(data=fasta_dict).drop_duplicates(subset='sequence_name', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_of_columns=1000\n",
    "def find_n_tags(seq_data, n_tags_index):\n",
    "    \n",
    "    seq_names = []\n",
    "    sequences = []\n",
    "    for val in seq_data:\n",
    "        inner=[]\n",
    "        seq=\"\"\n",
    "        for idx in n_tags_index:\n",
    "            inner.append(val[idx])\n",
    "        sequences.append(Seq(seq.join(inner)))\n",
    "        seq_names.append(val[0])\n",
    "    return sequences, seq_names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_tags_based_on_entropy(seq_data):\n",
    "    entropys_list=[]\n",
    "    for val in seq_data.T[1:]:\n",
    "        dash,A,C,T,G,entropy=0,0,0,0,0,0\n",
    "        for neu in val:\n",
    "            if neu == \"-\":\n",
    "                dash+=1\n",
    "            elif neu == \"A\":\n",
    "                A+=1\n",
    "            elif neu == \"C\":\n",
    "                C+=1\n",
    "            elif neu == \"T\":\n",
    "                T+=1\n",
    "            elif neu == \"G\":\n",
    "                G+=1\n",
    "        total = A+C+T+G\n",
    "        if (total > 0):\n",
    "            n_a_freq = A/ total\n",
    "            n_c_freq = C/ total\n",
    "            n_t_freq = T/ total\n",
    "            n_g_freq = G/ total\n",
    "            entropy_a = n_a_freq * math.log2(n_a_freq) if n_a_freq > 0 else 0\n",
    "            entropy_c = n_c_freq * math.log2(n_c_freq) if n_c_freq > 0 else 0\n",
    "            entropy_g = n_t_freq * math.log2(n_t_freq) if n_t_freq > 0 else 0\n",
    "            entropy_t = n_g_freq * math.log2(n_g_freq) if n_g_freq > 0 else 0\n",
    "            entropy = entropy + entropy_a + entropy_c + entropy_g + entropy_t\n",
    "        entropys_list.append(abs(entropy))\n",
    "    return entropys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_tags_based_on_hamming(seq_data):\n",
    "    dist_list=[]\n",
    "    for val in seq_data.T[1:]:\n",
    "        dash,A,C,T,G,hamming=0,0,0,0,0,0\n",
    "        for neu in val:\n",
    "            if neu == \"-\":\n",
    "                dash+=1\n",
    "            elif neu == \"A\":\n",
    "                A+=1\n",
    "            elif neu == \"C\":\n",
    "                C+=1\n",
    "            elif neu == \"T\":\n",
    "                T+=1\n",
    "            elif neu == \"G\":\n",
    "                G+=1\n",
    "        total = A + C + T + G + dash\n",
    "        max_actg = max(A,C,T,G)\n",
    "        hamming = total - (max_actg + dash)\n",
    "        dist_list.append(hamming)\n",
    "    return dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_tags(no_of_columns):\n",
    "    print(no_of_columns)\n",
    "    seq_data=[]\n",
    "    for val in fasta_df.values:\n",
    "        seq=list(val[2])\n",
    "        seq.insert(0,val[0])\n",
    "        seq_data.append(seq)\n",
    "        \n",
    "    # for entropy\n",
    "    # entropys_list = sort_tags_based_on_entropy(np.array(seq_data))\n",
    "    # sorted_tags_wrt_entropy = np.argsort(entropys_list)\n",
    "    # n_tags_index = [x + 1 for x in sorted_tags_wrt_entropy[::-1][:no_of_columns]]\n",
    "    dist_list = sort_tags_based_on_hamming(np.array(seq_data))\n",
    "    sorted_tags_wrt_hamming = np.argsort(dist_list)\n",
    "    n_tags_index = [x + 1 for x in sorted_tags_wrt_hamming[::-1][:no_of_columns]]\n",
    "    \n",
    "    return find_n_tags(seq_data, n_tags_index)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "seqs, seq_names = get_n_tags(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster=[]\n",
    "for val in seq_names:\n",
    "    cluster.append(cluster_info_dict[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dict = {'sequence_name':seq_names , 'cluster_name':cluster,'sequence': seqs}\n",
    "fasta_df = pd.DataFrame(data=fasta_dict).drop_duplicates(subset='sequence_name', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fasta_df[\"sequence\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/1k_tags_3k_hamm.pkl\",fasta_df.values)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4908088c429649f77d7bb00b95b8c5a0c65ad360a2d72d35695b2616fad4df79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('entropy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
